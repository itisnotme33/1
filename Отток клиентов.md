


```python

```

<h1>Содержание<span class="tocSkip"></span></h1>
<div class="toc"><ul class="toc-item"><li><span><a href="#Подготовка-данных" data-toc-modified-id="Подготовка-данных-1"><span class="toc-item-num">1&nbsp;&nbsp;</span>Подготовка данных</a></span></li><li><span><a href="#Исследование-задачи" data-toc-modified-id="Исследование-задачи-2"><span class="toc-item-num">2&nbsp;&nbsp;</span>Исследование задачи</a></span></li><li><span><a href="#Борьба-с-дисбалансом" data-toc-modified-id="Борьба-с-дисбалансом-3"><span class="toc-item-num">3&nbsp;&nbsp;</span>Борьба с дисбалансом</a></span></li><li><span><a href="#Тестирование-модели" data-toc-modified-id="Тестирование-модели-4"><span class="toc-item-num">4&nbsp;&nbsp;</span>Тестирование модели</a></span></li><li><span><a href="#Чек-лист-готовности-проекта" data-toc-modified-id="Чек-лист-готовности-проекта-5"><span class="toc-item-num">5&nbsp;&nbsp;</span>Чек-лист готовности проекта</a></span></li></ul></div>

# Отток клиентов

Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.

Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. 

Постройте модель с предельно большим значением *F1*-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте *F1*-меру на тестовой выборке самостоятельно.

Дополнительно измеряйте *AUC-ROC*, сравнивайте её значение с *F1*-мерой.

Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)

## Подготовка данных


```python
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score
from sklearn.preprocessing import StandardScaler
from tqdm import tqdm
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from sklearn.utils import shuffle
```


```python
data = pd.read_csv('/datasets/Churn.csv')
data.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 10000 entries, 0 to 9999
    Data columns (total 14 columns):
     #   Column           Non-Null Count  Dtype  
    ---  ------           --------------  -----  
     0   RowNumber        10000 non-null  int64  
     1   CustomerId       10000 non-null  int64  
     2   Surname          10000 non-null  object 
     3   CreditScore      10000 non-null  int64  
     4   Geography        10000 non-null  object 
     5   Gender           10000 non-null  object 
     6   Age              10000 non-null  int64  
     7   Tenure           9091 non-null   float64
     8   Balance          10000 non-null  float64
     9   NumOfProducts    10000 non-null  int64  
     10  HasCrCard        10000 non-null  int64  
     11  IsActiveMember   10000 non-null  int64  
     12  EstimatedSalary  10000 non-null  float64
     13  Exited           10000 non-null  int64  
    dtypes: float64(3), int64(8), object(3)
    memory usage: 1.1+ MB





```python
data.head()
```





<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>RowNumber</th>
      <th>CustomerId</th>
      <th>Surname</th>
      <th>CreditScore</th>
      <th>Geography</th>
      <th>Gender</th>
      <th>Age</th>
      <th>Tenure</th>
      <th>Balance</th>
      <th>NumOfProducts</th>
      <th>HasCrCard</th>
      <th>IsActiveMember</th>
      <th>EstimatedSalary</th>
      <th>Exited</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>15634602</td>
      <td>Hargrave</td>
      <td>619</td>
      <td>France</td>
      <td>Female</td>
      <td>42</td>
      <td>2.0</td>
      <td>0.00</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>101348.88</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>15647311</td>
      <td>Hill</td>
      <td>608</td>
      <td>Spain</td>
      <td>Female</td>
      <td>41</td>
      <td>1.0</td>
      <td>83807.86</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>112542.58</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>15619304</td>
      <td>Onio</td>
      <td>502</td>
      <td>France</td>
      <td>Female</td>
      <td>42</td>
      <td>8.0</td>
      <td>159660.80</td>
      <td>3</td>
      <td>1</td>
      <td>0</td>
      <td>113931.57</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>15701354</td>
      <td>Boni</td>
      <td>699</td>
      <td>France</td>
      <td>Female</td>
      <td>39</td>
      <td>1.0</td>
      <td>0.00</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>93826.63</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>15737888</td>
      <td>Mitchell</td>
      <td>850</td>
      <td>Spain</td>
      <td>Female</td>
      <td>43</td>
      <td>2.0</td>
      <td>125510.82</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>79084.10</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




```python
data.duplicated().sum()
```




    0



Явных дубликатов нет


```python
data = data.dropna()
```

Удалим пропуски, так так их меньше 10%



```python
data.isna().sum()
```




    RowNumber          0
    CustomerId         0
    Surname            0
    CreditScore        0
    Geography          0
    Gender             0
    Age                0
    Tenure             0
    Balance            0
    NumOfProducts      0
    HasCrCard          0
    IsActiveMember     0
    EstimatedSalary    0
    Exited             0
    dtype: int64



Применим OHE к столбцам Geography и Gender


```python
data['Geography'].unique()
```




    array(['France', 'Spain', 'Germany'], dtype=object)




```python
data['Gender'].unique()
```




    array(['Female', 'Male'], dtype=object)




```python
data = pd.get_dummies(data, columns=['Geography', 'Gender'], drop_first=True)
```


## Исследование задачи

Исследуйте баланс классов, обучите модель без учёта дисбаланса. Кратко опишите выводы


```python
data['Exited'].value_counts() #баланс классов
```




    0    7237
    1    1854
    Name: Exited, dtype: int64






```python
class_frequency = data['Exited'].value_counts(normalize=True)
print(class_frequency)
class_frequency.plot(kind='bar')
```

    0    0.796062
    1    0.203938
    Name: Exited, dtype: float64





    <AxesSubplot:>




    
![png](output_35_2.png)
    


Соотношение - 80/20. Наблюдается дисбаланс.

Разделим исходные данные на обучающую и тестовую выборки, а потом на обучающую, валидационную и тестовую выборки(3:1:1)


```python
features = data.drop(['Exited', 'Surname', 'CustomerId', 'RowNumber'], axis=1)
target = data['Exited']

features_train, features_test, target_train, target_test = train_test_split(
    features, target, test_size=0.4, random_state=12345)

features_valid, features_test, target_valid, target_test = train_test_split(
    features_test, target_test, test_size=0.5, random_state=12345)


```

Применим масштабирование к столбцам CreditScore, Balance, EstimatedSalary


```python
numeric = ['CreditScore', 'Balance', 'EstimatedSalary']

scaler = StandardScaler()
scaler.fit(features_train[numeric])

features_train[numeric] = scaler.transform(features_train[numeric])
features_valid[numeric] = scaler.transform(features_valid[numeric])
features_test[numeric] = scaler.transform(features_test[numeric])

pd.options.mode.chained_assignment = None
```



Проконтролируем разбиение


```python
print(features_train.shape)
print(target_train.shape)
```

    (5454, 11)
    (5454,)



```python
print(features_valid.shape)
print(target_valid.shape)

print(features_test.shape)
print(target_test.shape)
```

    (1818, 11)
    (1818,)
    (1819, 11)
    (1819,)



DecisionTreeClassifier


```python
best_model_dt = None
best_result_dt = 0
for depth in range(1, 11):
    model_dt = DecisionTreeClassifier(random_state=12345, max_depth=depth)
    model_dt.fit(features_train, target_train)
    predictions_valid_dt = model_dt.predict(features_valid)
    result_dt = f1_score(target_valid, predictions_valid_dt)
    if result_dt > best_result_dt:
        best_model_dt = model_dt
        best_depth_dt = depth
        best_result_dt = result_dt

print(best_model_dt) 
print('f1:', result_dt)
```

    DecisionTreeClassifier(max_depth=7, random_state=12345)
    f1: 0.5130568356374808



RandomForestClassifier


```python
best_model_rf = None
best_result_rf = 0
best_est_rf = 0
best_depth_rf = 0
for est in tqdm(range(1, 11)):
    for depth in range(1, 11):
        model_rf = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)
        model_rf.fit(features_train, target_train)
        predictions_valid_rf = model_rf.predict(features_valid)
        result_rf = f1_score(predictions_valid_rf, target_valid)
        if result_rf > best_result_rf:
            best_model_rf = model_rf
            best_result_rf = result_rf
            best_est_rf = est
            best_depth_rf = depth
            
print(best_model_rf)
print('f1:', result_rf)
```

    100%|██████████| 10/10 [00:02<00:00,  4.05it/s]

    RandomForestClassifier(max_depth=4, n_estimators=1, random_state=12345)
    f1: 0.5551839464882943


    


LogisticRegression


```python
model_lr = LogisticRegression(random_state=12345, solver='liblinear')
model_lr.fit(features_train, target_train)
predictions_valid_lr = model_lr.predict(features_valid)

print("f1:", f1_score(target_valid, predictions_valid_lr))
```

    f1: 0.3046092184368738


Наивысший показатель f1 у модели RandomForestClassifier.



## Борьба с дисбалансом

Улучшите качество модели, учитывая дисбаланс классов. Обучите разные модели и найдите лучшую. Кратко опишите выводы.

Применим взвешивание классов



DecisionTreeClassifier


```python
best_model_dt = None
best_result_dt = 0
for depth in range(1, 11):
    model_dt = DecisionTreeClassifier(random_state=12345, max_depth=depth, class_weight='balanced')
    model_dt.fit(features_train, target_train)
    predictions_valid_dt = model_dt.predict(features_valid)
    result_dt = f1_score(target_valid, predictions_valid_dt)
    if result_dt > best_result_dt:
        best_model_dt = model_dt
        best_depth = depth
        best_result_dt = result_dt
        
print(best_model_dt)
print('f1:', result_dt)
```

    DecisionTreeClassifier(class_weight='balanced', max_depth=5, random_state=12345)
    f1: 0.5164113785557987


RandomForestClassifier


```python
best_model_rf = None
best_result_rf = 0
best_est_rf = 0
best_depth_rf = 0
for est in tqdm(range(1, 11)):
    for depth in range(1, 11):
        model_rf = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth, class_weight='balanced')
        model_rf.fit(features_train, target_train)
        predictions_valid_rf = model_rf.predict(features_valid)
        result_rf = f1_score(predictions_valid_rf, target_valid)
        if result_rf > best_result_rf:
            best_model_rf = model_rf
            best_result_rf = result_rf
            best_est_rf = est
            best_depth_rf = depth
            
print(best_model_rf)
print('f1:', result_rf)

```

    100%|██████████| 10/10 [00:02<00:00,  4.01it/s]

    RandomForestClassifier(class_weight='balanced', max_depth=9, n_estimators=10,
                           random_state=12345)
    f1: 0.5840707964601769


    


LogisticRegression


```python
model_lr = LogisticRegression(random_state=12345, solver='liblinear', class_weight='balanced')
model_lr.fit(features_train, target_train)
predictions_valid_lr = model_lr.predict(features_valid)

print("f1:", f1_score(target_valid, predictions_valid_lr))
```

    f1: 0.5101289134438306


Сделаем увеличение выборки



DecisionTreeClassifier


```python
def upsample(features, target, repeat):
    features_zeros = features[target == 0]
    features_ones = features[target == 1]
    target_zeros = target[target == 0]
    target_ones = target[target == 1]

    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)
    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)
    
    features_upsampled, target_upsampled = shuffle(
        features_upsampled, target_upsampled, random_state=12345)
    
    return features_upsampled, target_upsampled

features_upsampled, target_upsampled = upsample(features_train, target_train, 4)

model_dt = DecisionTreeClassifier(random_state=12345, max_depth=depth)
model_dt.fit(features_upsampled, target_upsampled)
predictions_valid_dt = model_dt.predict(features_valid)

print("f1:", f1_score(target_valid, predictions_valid_dt))
```

    f1: 0.5059978189749182




RandomForestClassifier


```python
def upsample(features, target, repeat):
    features_zeros = features[target == 0]
    features_ones = features[target == 1]
    target_zeros = target[target == 0]
    target_ones = target[target == 1]

    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)
    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)
    
    features_upsampled, target_upsampled = shuffle(
        features_upsampled, target_upsampled, random_state=12345)
    
    return features_upsampled, target_upsampled

features_upsampled, target_upsampled = upsample(features_train, target_train, 4)

model_rf = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)
model_rf.fit(features_upsampled, target_upsampled)
predictions_valid_rf = model_rf.predict(features_valid)

print("f1:", f1_score(target_valid, predictions_valid_rf))
```

    f1: 0.5952380952380951




LogisticRegression


```python
def upsample(features, target, repeat):
    features_zeros = features[target == 0]
    features_ones = features[target == 1]
    target_zeros = target[target == 0]
    target_ones = target[target == 1]

    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)
    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)
    
    features_upsampled, target_upsampled = shuffle(
        features_upsampled, target_upsampled, random_state=12345)
    
    return features_upsampled, target_upsampled

features_upsampled, target_upsampled = upsample(features_train, target_train, 4)

model_lr = LogisticRegression(random_state=12345, solver='liblinear')
model_lr.fit(features_upsampled, target_upsampled)
predicted_valid = model_lr.predict(features_valid)

print("f1:", f1_score(target_valid, predicted_valid))
```

    f1: 0.5072463768115941


По результатам апсэмплинга также лучший показатель f1 у модели RandomForestClassifier. На ней и проведем финальное тестирование.


## Тестирование модели

Проведите финальное тестирование.


```python
model_best = RandomForestClassifier(
    random_state=12345, max_depth = 9, n_estimators = 10, class_weight='balanced')

model_best.fit(features_train, target_train) 
predictions = model_best.predict(features_test)
result = f1_score(target_test, predictions)

print("f1 лучшей модели на тестовой выборке:", result)
```

    f1 лучшей модели на тестовой выборке: 0.5936675461741425




Значение f1 превышает требуемые 0.59


```python
probabilities_valid = model_best.predict_proba(features_valid)
probabilities_one_valid = probabilities_valid[:, 1]

fpr, tpr, thresholds = roc_curve(target_valid, probabilities_one_valid)

plt.figure()

plt.plot(fpr, tpr)

plt.plot([0, 1], [0, 1], linestyle='--')

plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])

plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')

plt.title('ROC-кривая')
plt.show()

auc_roc = roc_auc_score(target_valid, probabilities_one_valid)
print('auc_roc:', auc_roc)
```


    
![png](output_94_0.png)
    


    auc_roc: 0.8689634924170329




Удалось достичь требуемого значения f1, показатель auc_roc близок к единице, это выше случайных 0.5

Вывод: по результатам исследования трех моделей мы установили лучшую - это RandomForestClassifier. Изначально наблюдался дисбаланс классов(80/20), который мы устранили с помощью их взвешивания и апсэмплинга. Удалось добиться повышения F1-меры. В итоге на финальном тестировании нам удалось получить требуемое значение f1 - 0.59, значение auc_roc также выше константной модели.

