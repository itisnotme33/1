
#  Прогнозирование заказов такси

Компания «Чётенькое такси» собрала исторические данные о заказах такси в аэропортах. Чтобы привлекать больше водителей в период пиковой нагрузки, нужно спрогнозировать количество заказов такси на следующий час. Постройте модель для такого предсказания.

Значение метрики *RMSE* на тестовой выборке должно быть не больше 48.

Вам нужно:

1. Загрузить данные и выполнить их ресемплирование по одному часу.
2. Проанализировать данные.
3. Обучить разные модели с различными гиперпараметрами. Сделать тестовую выборку размером 10% от исходных данных.
4. Проверить данные на тестовой выборке и сделать выводы.


Данные лежат в файле `taxi.csv`. Количество заказов находится в столбце `num_orders` (от англ. *number of orders*, «число заказов»).

<h1>Содержание<span class="tocSkip"></span></h1>
<div class="toc"><ul class="toc-item"><li><span><a href="#Подготовка" data-toc-modified-id="Подготовка-1"><span class="toc-item-num">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href="#Анализ" data-toc-modified-id="Анализ-2"><span class="toc-item-num">2&nbsp;&nbsp;</span>Анализ</a></span></li><li><span><a href="#Обучение" data-toc-modified-id="Обучение-3"><span class="toc-item-num">3&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href="#Тестирование" data-toc-modified-id="Тестирование-4"><span class="toc-item-num">4&nbsp;&nbsp;</span>Тестирование</a></span></li><li><span><a href="#Чек-лист-проверки" data-toc-modified-id="Чек-лист-проверки-5"><span class="toc-item-num">5&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>

## Подготовка


```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.seasonal import seasonal_decompose
from sklearn.linear_model import LinearRegression
from lightgbm import LGBMRegressor
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import TimeSeriesSplit
```


```python
data =  pd.read_csv('/datasets/taxi.csv')
data.head()
```





<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>num_orders</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2018-03-01 00:00:00</td>
      <td>9</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2018-03-01 00:10:00</td>
      <td>14</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2018-03-01 00:20:00</td>
      <td>28</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2018-03-01 00:30:00</td>
      <td>20</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2018-03-01 00:40:00</td>
      <td>32</td>
    </tr>
  </tbody>
</table>
</div>




```python
data.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 26496 entries, 0 to 26495
    Data columns (total 2 columns):
     #   Column      Non-Null Count  Dtype 
    ---  ------      --------------  ----- 
     0   datetime    26496 non-null  object
     1   num_orders  26496 non-null  int64 
    dtypes: int64(1), object(1)
    memory usage: 414.1+ KB



```python
data.describe()
```





<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>num_orders</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>26496.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>14.070463</td>
    </tr>
    <tr>
      <th>std</th>
      <td>9.211330</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>8.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>13.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>19.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>119.000000</td>
    </tr>
  </tbody>
</table>
</div>




```python
data['datetime']=pd.to_datetime(data['datetime'])
```


```python
data=data.set_index('datetime')
```


```python
data
```





<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>num_orders</th>
    </tr>
    <tr>
      <th>datetime</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2018-03-01 00:00:00</th>
      <td>9</td>
    </tr>
    <tr>
      <th>2018-03-01 00:10:00</th>
      <td>14</td>
    </tr>
    <tr>
      <th>2018-03-01 00:20:00</th>
      <td>28</td>
    </tr>
    <tr>
      <th>2018-03-01 00:30:00</th>
      <td>20</td>
    </tr>
    <tr>
      <th>2018-03-01 00:40:00</th>
      <td>32</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>2018-08-31 23:10:00</th>
      <td>32</td>
    </tr>
    <tr>
      <th>2018-08-31 23:20:00</th>
      <td>24</td>
    </tr>
    <tr>
      <th>2018-08-31 23:30:00</th>
      <td>27</td>
    </tr>
    <tr>
      <th>2018-08-31 23:40:00</th>
      <td>39</td>
    </tr>
    <tr>
      <th>2018-08-31 23:50:00</th>
      <td>53</td>
    </tr>
  </tbody>
</table>
<p>26496 rows × 1 columns</p>
</div>




```python
data.info()
```

    <class 'pandas.core.frame.DataFrame'>
    DatetimeIndex: 26496 entries, 2018-03-01 00:00:00 to 2018-08-31 23:50:00
    Data columns (total 1 columns):
     #   Column      Non-Null Count  Dtype
    ---  ------      --------------  -----
     0   num_orders  26496 non-null  int64
    dtypes: int64(1)
    memory usage: 414.0 KB


Ресемплирование по одному часу


```python
data = data.resample('1H').sum()
data.head()
```





<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>num_orders</th>
    </tr>
    <tr>
      <th>datetime</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2018-03-01 00:00:00</th>
      <td>124</td>
    </tr>
    <tr>
      <th>2018-03-01 01:00:00</th>
      <td>85</td>
    </tr>
    <tr>
      <th>2018-03-01 02:00:00</th>
      <td>71</td>
    </tr>
    <tr>
      <th>2018-03-01 03:00:00</th>
      <td>66</td>
    </tr>
    <tr>
      <th>2018-03-01 04:00:00</th>
      <td>43</td>
    </tr>
  </tbody>
</table>
</div>




```python
data.isna().sum()
```




    num_orders    0
    dtype: int64



 

## Анализ

График по количеству заказов в час

```python

data.plot(figsize=(15,10))
plt.title('По количеству заказов в час')
plt.xlabel('Дата')
plt.ylabel('Количество заказов')
```




    Text(0, 0.5, 'Количество заказов')




    
![png](output_20_1.png)
    


Наблюдается тенденция по увеличению количества заказов


```python
decomposed = seasonal_decompose(data)
```

Тренд

```python

decomposed.trend.plot(figsize=(15,10))
plt.title('Тренд')
plt.xlabel('Дата')
plt.ylabel('Количество заказов')
```




    Text(0, 0.5, 'Количество заказов')




    
![png](output_23_1.png)
    


Тренд растет

Сезонность

```python

decomposed.seasonal.plot(figsize=(15,10))
plt.title('Сезонность')
plt.xlabel('Дата')
plt.ylabel('Количество заказов')
```




    Text(0, 0.5, 'Количество заказов')




    
![png](output_25_1.png)
    


Количество заказов не зависит от сезонности

Сезонность в меньшем масштабе, например три дня августа

```python

decomposed.seasonal['2018-08-01':'2018-08-03'].plot(figsize=(15,10))
plt.title('Сезонность')
plt.xlabel('Дата')
plt.ylabel('Количество заказов')
```




    Text(0, 0.5, 'Количество заказов')




    
![png](output_27_1.png)
    

Остаток

```python

decomposed.resid.plot(figsize=(15,10))
plt.title('Остаток декомпозиции')
plt.xlabel('Дата')
plt.ylabel('Количество заказов')
```




    Text(0, 0.5, 'Количество заказов')




    
![png](output_28_1.png)
    



```python

```


```python
data['rolling_mean'] = data.rolling(10).mean()
data.plot(figsize=(15,10))
plt.title('Скользящее среднее')
plt.xlabel('Дата')
plt.ylabel('Количество заказов')
plt.show()
```


    
![png](output_30_0.png)
    



```python
print('Скользящее среднее = ',decomposed.trend.mean())
```

    Скользящее среднее =  84.26974233454767




Вывод: на графике тренда видим постепенное увеличение числа заказов весной, летом услуги такси намного более востребованны. Для анализа сезонности не хватает данных: у нас только промежуток в полгода. Но если смотреть на график трех дней, можно отметить увеличение количества заказов в течение дня, с утра и до завершения суток, когда достигается максимальное значение.

## Обучение

Напишем функцию для признаков


```python
def make_features(data, max_lag, rolling_mean_size):
    
    data['dayofweek'] = data.index.dayofweek
    data['hour'] = data.index.hour
    data['day'] = data.index.day
    
    
    for lag in range(1, max_lag + 1):
        data['lag_{}'.format(lag)] = data['num_orders'].shift(lag)

    data['rolling_mean'] = data['num_orders'].shift().rolling(rolling_mean_size).mean()
    
    return data
```



```python
make_features(data, 24, 10)
```





<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>num_orders</th>
      <th>rolling_mean</th>
      <th>dayofweek</th>
      <th>hour</th>
      <th>day</th>
      <th>lag_1</th>
      <th>lag_2</th>
      <th>lag_3</th>
      <th>lag_4</th>
      <th>lag_5</th>
      <th>...</th>
      <th>lag_15</th>
      <th>lag_16</th>
      <th>lag_17</th>
      <th>lag_18</th>
      <th>lag_19</th>
      <th>lag_20</th>
      <th>lag_21</th>
      <th>lag_22</th>
      <th>lag_23</th>
      <th>lag_24</th>
    </tr>
    <tr>
      <th>datetime</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2018-03-01 00:00:00</th>
      <td>124</td>
      <td>NaN</td>
      <td>3</td>
      <td>0</td>
      <td>1</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2018-03-01 01:00:00</th>
      <td>85</td>
      <td>NaN</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>124.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2018-03-01 02:00:00</th>
      <td>71</td>
      <td>NaN</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>85.0</td>
      <td>124.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2018-03-01 03:00:00</th>
      <td>66</td>
      <td>NaN</td>
      <td>3</td>
      <td>3</td>
      <td>1</td>
      <td>71.0</td>
      <td>85.0</td>
      <td>124.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2018-03-01 04:00:00</th>
      <td>43</td>
      <td>NaN</td>
      <td>3</td>
      <td>4</td>
      <td>1</td>
      <td>66.0</td>
      <td>71.0</td>
      <td>85.0</td>
      <td>124.0</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2018-08-31 19:00:00</th>
      <td>136</td>
      <td>173.3</td>
      <td>4</td>
      <td>19</td>
      <td>31</td>
      <td>207.0</td>
      <td>217.0</td>
      <td>197.0</td>
      <td>116.0</td>
      <td>133.0</td>
      <td>...</td>
      <td>268.0</td>
      <td>99.0</td>
      <td>230.0</td>
      <td>194.0</td>
      <td>276.0</td>
      <td>246.0</td>
      <td>158.0</td>
      <td>198.0</td>
      <td>142.0</td>
      <td>72.0</td>
    </tr>
    <tr>
      <th>2018-08-31 20:00:00</th>
      <td>154</td>
      <td>166.6</td>
      <td>4</td>
      <td>20</td>
      <td>31</td>
      <td>136.0</td>
      <td>207.0</td>
      <td>217.0</td>
      <td>197.0</td>
      <td>116.0</td>
      <td>...</td>
      <td>78.0</td>
      <td>268.0</td>
      <td>99.0</td>
      <td>230.0</td>
      <td>194.0</td>
      <td>276.0</td>
      <td>246.0</td>
      <td>158.0</td>
      <td>198.0</td>
      <td>142.0</td>
    </tr>
    <tr>
      <th>2018-08-31 21:00:00</th>
      <td>159</td>
      <td>162.9</td>
      <td>4</td>
      <td>21</td>
      <td>31</td>
      <td>154.0</td>
      <td>136.0</td>
      <td>207.0</td>
      <td>217.0</td>
      <td>197.0</td>
      <td>...</td>
      <td>35.0</td>
      <td>78.0</td>
      <td>268.0</td>
      <td>99.0</td>
      <td>230.0</td>
      <td>194.0</td>
      <td>276.0</td>
      <td>246.0</td>
      <td>158.0</td>
      <td>198.0</td>
    </tr>
    <tr>
      <th>2018-08-31 22:00:00</th>
      <td>223</td>
      <td>162.1</td>
      <td>4</td>
      <td>22</td>
      <td>31</td>
      <td>159.0</td>
      <td>154.0</td>
      <td>136.0</td>
      <td>207.0</td>
      <td>217.0</td>
      <td>...</td>
      <td>46.0</td>
      <td>35.0</td>
      <td>78.0</td>
      <td>268.0</td>
      <td>99.0</td>
      <td>230.0</td>
      <td>194.0</td>
      <td>276.0</td>
      <td>246.0</td>
      <td>158.0</td>
    </tr>
    <tr>
      <th>2018-08-31 23:00:00</th>
      <td>205</td>
      <td>170.8</td>
      <td>4</td>
      <td>23</td>
      <td>31</td>
      <td>223.0</td>
      <td>159.0</td>
      <td>154.0</td>
      <td>136.0</td>
      <td>207.0</td>
      <td>...</td>
      <td>182.0</td>
      <td>46.0</td>
      <td>35.0</td>
      <td>78.0</td>
      <td>268.0</td>
      <td>99.0</td>
      <td>230.0</td>
      <td>194.0</td>
      <td>276.0</td>
      <td>246.0</td>
    </tr>
  </tbody>
</table>
<p>4416 rows × 29 columns</p>
</div>




Разделим на выборки, тестовую сделаем размером 10% от исходных данных


```python
train,test = train_test_split(data, shuffle=False, test_size=0.1)
```

 


```python
train = train.dropna()
```


```python
features_train = train.drop(['num_orders'],axis=1)
target_train = train['num_orders']
```


```python
features_test = test.drop(['num_orders'],axis=1)
target_test = test['num_orders']
```


```python

```

Проконтролируем размер


```python
features_train.shape
```




    (3950, 28)




```python
target_train.shape
```




    (3950,)




```python
features_test.shape
```




    (442, 28)




```python
target_test.shape
```




    (442,)



LinearRegression


```python
%%time
tscv = TimeSeriesSplit(n_splits=5)

regressor = LinearRegression()
print('# Train for root_mean_squared_error')
cv_RMSE_LR = (cross_val_score(regressor, 
                             features_train, 
                             target_train, 
                             cv=tscv, 
                             scoring='neg_mean_squared_error').mean() * -1) ** 0.5
print('Mean RMSE from CV of LinearRegression =', cv_RMSE_LR)
```

    # Train for root_mean_squared_error
    Mean RMSE from CV of LinearRegression = 27.372958358457
    CPU times: user 224 ms, sys: 734 ms, total: 958 ms
    Wall time: 898 ms


LGBMR


```python
%%time
model = LGBMRegressor()
parameters = [{'num_leaves':[25,50], 'learning_rate':[0.1,0.3], 'random_state':[12345]}]

tscv = TimeSeriesSplit(n_splits=5)

clf = GridSearchCV(model, parameters, scoring='neg_mean_squared_error', cv=tscv)
clf.fit(features_train, target_train)

print(clf.best_params_)
print()

mts = clf.cv_results_['mean_test_score']

rmse = (max(mts) * -1) ** 0.5
print('RMSE модели LGBMR =',rmse)
```


```python

```



## Тестирование

На тестовой выборке проверим модель LGBMR, так как она показала лучший результат


```python
model = LGBMRegressor(learning_rate=0.1, num_leaves=25, random_state=12345)
model.fit(features_train, target_train)
predictions = model.predict(features_test)
rmse = mean_squared_error(target_test, predictions) ** 0.5
print('RMSE модели LGBMR на тестовой выборке =', rmse)
```


        


Вывод: перед нами стояла задача создания модели, прогнозирующей количество заказов такси на следующий час. Лучшие результаты показала модель LGBMRegressor. Нам удалось добиться нужного значения метрики: RMSE = 41. Это меньше 48. Требование заказчика выполнено.

