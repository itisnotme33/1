

# Рекомендация тарифов

В нашем распоряжении данные о поведении клиентов, которые уже перешли на эти тарифы. Нужно построить модель для задачи классификации, которая выберет подходящий тариф,
построить модель с максимально большим значением *accuracy*, довести долю правильных ответов по крайней мере до 0.75, проверить *accuracy* на тестовой выборке.



## Изучение данных


```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from tqdm import tqdm
```


```python
data = pd.read_csv('/datasets/users_behavior.csv')

data.info()
data.head()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 3214 entries, 0 to 3213
    Data columns (total 5 columns):
     #   Column    Non-Null Count  Dtype  
    ---  ------    --------------  -----  
     0   calls     3214 non-null   float64
     1   minutes   3214 non-null   float64
     2   messages  3214 non-null   float64
     3   mb_used   3214 non-null   float64
     4   is_ultra  3214 non-null   int64  
    dtypes: float64(4), int64(1)
    memory usage: 125.7 KB






<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>calls</th>
      <th>minutes</th>
      <th>messages</th>
      <th>mb_used</th>
      <th>is_ultra</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>40.0</td>
      <td>311.90</td>
      <td>83.0</td>
      <td>19915.42</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>85.0</td>
      <td>516.75</td>
      <td>56.0</td>
      <td>22696.96</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>77.0</td>
      <td>467.66</td>
      <td>86.0</td>
      <td>21060.45</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>106.0</td>
      <td>745.53</td>
      <td>81.0</td>
      <td>8437.39</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>66.0</td>
      <td>418.74</td>
      <td>1.0</td>
      <td>14502.75</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>









```python
data.duplicated().sum()
```




    0



Явных дубликатов нет





## Разбиение данные на выборки


```python
features = data.drop(['is_ultra'], axis=1)
target = data['is_ultra']                                                                           
```

Сначала разделим исходные данные на обучающую и тестовую выборки (60/40)


```python
features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.4, random_state=12345)
```

Затем разделим на обучающую, валидационную и тестовую выборки (60/40:2 = 60/20/20, то есть соотношение 3:1:1)


```python
features_valid, features_test, target_valid, target_test = train_test_split(features_test, target_test, test_size=0.5, random_state=12345)
```


```python
print(features_train.shape)
print(target_train.shape)
```

    (1928, 4)
    (1928,)



```python
print(features_valid.shape)
print(target_valid.shape)

print(features_test.shape)
print(target_test.shape)
```

    (643, 4)
    (643,)
    (643, 4)
    (643,)







## Исследование моделей

DecisionTreeClassifier


```python
best_model_dt = None
best_result_dt = 0
for depth in range(1, 11):
    model_dt = DecisionTreeClassifier(random_state=12345, max_depth=depth)
    model_dt.fit(features_train, target_train)
    predictions_dt = model_dt.predict(features_valid)
    result_dt = accuracy_score(predictions_dt, target_valid)
    if result_dt > best_result_dt:
        best_model_dt = model_dt
        best_result_dt = result_dt
        
print("Accuracy лучшей модели:", best_result_dt)        
```

    Accuracy лучшей модели: 0.7853810264385692







RandomForestClassifier


```python
best_model_rf = None
best_result_rf = 0
best_est_rf = 0
best_depth_rf = 0
for est in tqdm(range(1, 11)):
    for depth in range(1, 11):
        model_rf = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)
        model_rf.fit(features_train, target_train)
        predictions_valid_rf = model_rf.predict(features_valid)
        result_rf = accuracy_score(predictions_valid_rf, target_valid)
        if result_rf > best_result_rf:
            best_model_rf = model_rf
            best_result_rf = result_rf
            best_est_rf = est
            best_depth_rf = depth
            
print(best_model_rf) 
print("Accuracy лучшей модели:", best_result_rf)
```

    100%|██████████| 10/10 [00:01<00:00,  6.20it/s]

    RandomForestClassifier(max_depth=8, n_estimators=8, random_state=12345)
    Accuracy лучшей модели: 0.80248833592535


    





LogisticRegression


```python
model = LogisticRegression(random_state=12345, solver='lbfgs')
model.fit(features_train, target_train)
predictions_valid = model.predict(features_valid)
accuracy = accuracy_score(predictions_valid, target_valid)
print("Accuracy лучшей модели:", accuracy)
```

    Accuracy лучшей модели: 0.7107309486780715


Вывод: наивысший показатель accuracy у модели RandomForestClassifier. Ее и проверим на тестовой выборке.








## Проверка модели на тестовой выборке


```python
model = RandomForestClassifier(random_state=12345, max_depth=8, n_estimators=8)
model.fit(features_train, target_train)
accuracy = model.score(features_test, target_test)
print("Accuracy:", accuracy)
```

    Accuracy: 0.7962674961119751






## Проверка модели на адекватность


```python
data['is_ultra'].value_counts() / data.shape[0]
```




    0    0.693528
    1    0.306472
    Name: is_ultra, dtype: float64



Вывод: модель адекватна, так как ее accuracy выше, чем 0.693528






Вывод: по результатам исследований мы установили, что наибольшую долю правильных ответов нам дает модель RandomForestClassifier. При этом модель адекватна, то есть точнее случайной.

